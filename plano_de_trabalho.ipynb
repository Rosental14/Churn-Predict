{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<CENTER>\n",
    "\n",
    "# Plano de Trabalho - Projeto Churn Predict Telecomunicações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação das Bibliotecas\n",
    "\n",
    "Inicialmente serão importadas as bibliotecas que sejam necessárias para a execução do projeto e instaladas aquelas que ainda não tenham sido.\n",
    "Inicialmente, as bibliotecas que serão importadas são: **pandas, numpy, seaborn, matplotib e sklearn.** Caso alguma outra biblioteca ou módulo sejam necessários posteriormente, deverão também ser incluídos na primera célula de código.\n",
    "\n",
    "## Carregamento e visualização dos Dados\n",
    "\n",
    "Serão carregados os 4 DataFrames disponíveis. Para uma primeira visualização dos dados serão impressas as 5 primeiras linhas e também as informações principais do DataFrame (nomes das colunas, número de linhas, dados ausentes e tipos de dados) com o comando info.\n",
    "Neste momento serão avaliadas a consistência dos dados, a padronização dos nomes das colunas em snake_case, conversão de tipos de dados quando necessário e se existem linhas duplicadas.\n",
    "\n",
    "## Concatenar DataFrames\n",
    "Após verificar as informações básicas de cada DataFrame, será feito um merge para uní-los com base na coluna 'customer_id', pois é a informação comum que existe em todos os DataFrames. \n",
    "Após realizar a junção dos DataFrames, serão checadas novamente as informações para observarmos se algumas colunas contém dados ausentes, o que é esperado devido ao número diferente de linhas entre os DataFrames.\n",
    "\n",
    "### Criação da coluna Target\n",
    "Será criada uma coluna 'churn' com base na coluna 'end_date'. Se a coluna 'end_date estiver preenchida com 'No', 'NaN' ou 'NaT', significa que esse cliente não sofreu churn e, portanto, a coluna 'churn' será preenchida com o número 0. Caso a coluna 'end_date' tenha uma informação de data, significa que ele sofreu churn e a sua linha correspondente na coluna 'churn' será preenchida com o número 1.\n",
    "\n",
    "## Análise Exploratória de Dados\n",
    "Os dados serão inicialmente divididos em dados categóricos, dados numéricos e temporais.\n",
    "\n",
    "### Análise das colunas categóricas\n",
    "* Análise das distribuições de cada uma das colunas categóricas com o objetivo de checar a proporção de dados em cada uma das categorias contidas na coluna;\n",
    "* Impressão de um gráfico de barras para comparação visual da proporção de cada coluna;\n",
    "* Análise da Taxa de Churn em relação às variáveis categóricas, comparando-se em cada coluna do DataFrame quais as opções que mais refletem em churn por parte dos clientes;\n",
    "* Avaliação das despesas médias mensais e anuais dos clientes em relação às opções contidas nas variáveis categóricas;\n",
    "* Análise do comportamento dos clientes idosos em relação aos clientes não-idosos em relação às opções disponíveis.\n",
    "\n",
    "### Análise das colunas numéricas\n",
    "* Análise das distribuições e estatísticas descritivas;\n",
    "* Serão plotados histogramas para visualização da distribuição e boxplots para checagem de outliers;\n",
    "* Comparação das despesas médias mensal e total dos clientes que sofreram churn com os clientes que não sofreram.\n",
    "\n",
    "### Análise de Dados Temporais\n",
    "* Distribuição mensal de novos contratos e churns;\n",
    "* Análise de tendências e sazonalidade em relação a novos contratos, média de preços e tendências gerais de preferências dos clientes ao longo do tempo, avaliando todas as categorias disponíveis de serviços.\n",
    "\n",
    "## Feature Engineering\n",
    "Utilizando todas as informações levantadas na EDA realizada, serão criadas novas características que possam nos auxiliar na análise, assim como auxiliar nosso modelo a prever os motivos de churn.\n",
    "Alguns dos exemplos de colunas que podem ser criadas (ainda antes de realizar a EDA):\n",
    "- Coluna 'today': contendo o dia atual (criado com base na maior data observada nos dados). Será o mesmo dia para todas as observações, apenas para fim de cálculo de tempo de contrato;\n",
    "- Coluna 'duration': contendo o tempo de duração de contrato (os clientes que sofreram churn terão seus tempos calculados com a subtração da coluna 'end_date' por 'begin_date'. Clientes que não sofreram o churn terão seus tempos de contrato calculados subtraindo-se a coluna 'begin_date' da coluna'today');\n",
    "- Coluna 'services_number': contendo informação numérica de quantos serviços o cliente contratou;\n",
    "- Coluna 'avg_charges': contendo a média das despesas, dividindo-se a coluna 'total_charges' pela coluna 'duration' (com o tempo de contrato);\n",
    "\n",
    "### Remoção de colunas desnecessárias\n",
    "Nesta etapa serão removidas as colunas que não são úteis para o modelo, como por exemplo as colunas ('customer_id', 'begin_date', 'end_date', 'today'). Caso hajam mais colunas que sejam avaliadas como desnecessárias, elas serão eliminadas nesta etapa.\n",
    "\n",
    "### Conversão dos tipos de dados\n",
    "Após criação das colunas no processo de feature engineering, serão convertidos os tipos de dados para os mais adequados para treinamento dos modelos.\n",
    "Os dados categóricos serão convertidos para 'category' e caso haja alguma outra coluna com necessidade de conversão, ela será executada neste momento.\n",
    "\n",
    "### Divisão dos Dados\n",
    "Após a criação de novas características que sejam relevantes, assim como a exclusão de colunas que não sejam impactantes para o treinamento do modelo, será realizada a divisão dos dados nos conjuntos de treino, validação e teste.\n",
    "Primeiramente será definida a coluna 'churn' como target e as demais colunas restantes como features e, posteriormente divididas com train_test_split em conjuntos de treino, validação e teste, sendo que 70% dos dados serão destinados ao conjunto de treino, 15% para o conjunto de validação e 15% para o conjunto de teste.\n",
    "\n",
    "### Transformação dos Dados (Codificação dos Dados categóricos e Padronização dos dados numéricos)\n",
    "Será realizada a Codificação dos dados categóricos de acordo com a opção que melhor se enquadre com cada um deles, assim como a padronização dos dados numéricos usando StandardScaler.\n",
    "Nesta etapa será utilizado o fit_transform apenas no conjunto de treino, enquanto os conjuntos de validação e teste serão apenas transformados, evitando-se o vazamento das informações (data leakage)do conjunto de teste.\n",
    "\n",
    "### Clusterização\n",
    "Será utilizado Aprendizado Não-Supervisionado para clusterização com objetivo de encontrar segmentos de clientes similares para criar categorias específicas por tempo de contrato, gastos médios, tipos de serviços etc., e assim, contribuir ainda mais para o feature engineering, criando novas colunas de categorias.\n",
    "A clusterização será realizada somente no conjunto de treino separado anteriormente, depois os clusters serão aplicados aos conjuntos de validação e teste para posteriormente serem transformados (codificados ou padronizados) assim como realizado anteriormente com as características já existentes.\n",
    "\n",
    "## Tratamento do desequilíbrio de classes\n",
    "Em projetos de churn, o desequilíbrio de classes é uma questão comum, já que o número de clientes que sofrem churn costuma ser muito menor do que o número de clientes que permanecem com o contrato ativo. Nesta etapa será analisado se existe esse desequilíbrio na coluna 'churn' e qual a severidade dele. Se o desequilíbrio for grande, como esperado, usaremos a técnica de Superamostragem (técnica SMOTE) juntamente com o ajuste do parâmetros class_weight para 'balanced' (nos modelos que permitirem este ajuste). Não usaremos a técnica de subamostragem, pois o nosso conjunto de dados não é muito grande e poderíamos perder informações importantes neste caso.\n",
    "\n",
    "## Treinamento e avaliação dos modelos\n",
    "Após toda a preparação dos dados, serão treinados e avaliados os modelos simples (ainda sem ajustes dos hiperparâmetros).\n",
    "Serão utilizados os modelos: **LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, XGBClassifier, LightGBM, CatBoost e uma Rede Neural (MLP - Multi Layer Perceptron)**\n",
    "Para a avaliação do desempenho do modelo, serão utilizadas as métricas de: **AUC-ROC, F1_Score, Acurácia, Matriz de confusão, Precisão e Sensibilidade.** O resultado final deve basear-se nas métricas citadas, nesta ordem de importância. A matriz de confusão tem o objetivo de avaliar se o modelo obtém poucos resultados de Falso Negativo em relação aos resultados de Falso Positivo, pois o custo da perda de um cliente é maior do que o custo de oferecer promoções ou descontos a um cliente que não sofreria churn. Portanto, iremos buscar um modelo que possua uma sensibilidade maior, mas que também não cometa erros em exagero.\n",
    "\n",
    "## Tuning e Seleção do melhor modelo\n",
    "Após treinamento e avaliação de todos os modelos citados acima, serão escolhidos os 3 modelos com maior potencial para que seja realizado o ajuste de hiperparâmetros utilizando os dados de validação. Após os ajustes necessários, os modelos selecionados serão novamente avaliados com as mesmas métricas para a determinação do melhor modelo.\n",
    "\n",
    "\n",
    "**OBJETIVO:** obter AUC-ROC mínimo de 0.75\n",
    "\n",
    "\n",
    "## Referências\n",
    "\n",
    "Konstantin, T. Bank Churn Data Exploration And Churn Prediction. Kaggle. Acessado em 03 de outubro de 2024 através de <https://www.kaggle.com/code/thomaskonstantin/bank-churn-data-exploration-and-churn-prediction.> \n",
    "\n",
    "ISIK, M. Telecom Churn Prediction Learning ML Models. Kaggle. Acessado em 03 de outubro de 2024 através de <https://www.kaggle.com/code/mehmetisik/telecom-churn-prediction-learning-ml-models.>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".triple_ten",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
